{"cells":[{"cell_type":"markdown","metadata":{"id":"U3at1mhslz9v"},"source":["##掛載雲端硬碟\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ijtFdN9tl14V"},"outputs":[],"source":["# from google.colab import drive\n","# drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"q5bhyRZrl4X2"},"source":["##更改檔案所在路徑"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"f2RXiD5Bl6a2"},"outputs":[],"source":["# # Change to your own folder !!!\n","# %cd /content/drive/MyDrive/Colab\\ Notebooks/EAI_Lab4_2023"]},{"cell_type":"markdown","metadata":{"id":"gSal5HL0lTHA"},"source":["## Import library"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"6v2iM_kglWj-"},"outputs":[],"source":["from __future__ import print_function\n","import os\n","import argparse\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torchvision import datasets, transforms\n","from torch.autograd import Variable\n","\n","from models import vgg"]},{"cell_type":"markdown","metadata":{"id":"yFgiQGL6mq6W"},"source":["## 設定超參數(填空)"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"a8FQ-IsUmqtP"},"outputs":[],"source":["SPARSITY_REGULARIZATION = True\n","#### 設定λ(balance factor) ####\n","################################################\n","#          請填空          #\n","################################################\n","LAMBDA = 0.0001\n","\n","SEED = 1\n","TRAIN_BATCH_SIZE = 100\n","TEST_BATCH_SIZE = 1000\n","EPOCHS = 60\n","LEARNING_RATE = 0.1\n","MOMENTUM = 0.9\n","WEIGHT_DECAY = 1e-4\n","LOG_INTERVAL = 100\n","CUDA = True\n","\n","RESUME = False\n","START_EPOCH = 0\n","\n","WEIGHT_PATH = './model_weight/model_best.pth'\n"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"_Sa1Tmnym3Pn"},"outputs":[{"name":"stdout","output_type":"stream","text":["CUDA is not available\n"]}],"source":["if(torch.cuda.is_available()):\n","    CUDA = True\n","    kwargs = {'num_workers': 1, 'pin_memory': True}\n","    torch.cuda.manual_seed(SEED)\n","else:\n","    CUDA = False\n","    kwargs = {}\n"]},{"cell_type":"markdown","metadata":{"id":"fylf4FTlm7QX"},"source":["##下載資料集\n"]},{"cell_type":"markdown","metadata":{"id":"erS9S_76nUsG"},"source":["這裡將訓練集做Augmentation(Pad, RandCrop, Random)，測試集不用做Augmentation"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"vBW21uIHm_C-"},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 170498071/170498071 [00:35<00:00, 4774286.84it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Extracting ./data/cifar-10-python.tar.gz to ./data\n"]}],"source":["#### 資料集 ####\n","train_loader = torch.utils.data.DataLoader(\n","    datasets.CIFAR10('./data', train=True, download=True,\n","                   transform=transforms.Compose([\n","                       transforms.Pad(4),\n","                       transforms.RandomCrop(32),\n","                       transforms.RandomHorizontalFlip(),\n","                       transforms.ToTensor(),\n","                       transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n","                   ])),\n","    batch_size=TRAIN_BATCH_SIZE, shuffle=True, **kwargs)\n","\n","test_loader = torch.utils.data.DataLoader(\n","    datasets.CIFAR10('./data', train=False, transform=transforms.Compose([\n","                       transforms.ToTensor(),\n","                       transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n","                   ])),\n","    batch_size=TEST_BATCH_SIZE, shuffle=True, **kwargs)"]},{"cell_type":"markdown","metadata":{"id":"Is49FKBbuRj2"},"source":["## 定義模型與載入訓練好的權重"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"SUbUcHN4uQ89"},"outputs":[],"source":["model = vgg()\n","if CUDA:\n","    model.cuda()"]},{"cell_type":"markdown","metadata":{"id":"ZC8ECoKHu7iF"},"source":["##設定Optimizer，這裡使用Stocastic Gradient Descent"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"EQ-soeyWvGyM"},"outputs":[],"source":["optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE, momentum=MOMENTUM, weight_decay=WEIGHT_DECAY)"]},{"cell_type":"markdown","metadata":{"id":"txRrgb22vLD9"},"source":["##使用論文中稀疏化的方式更新參數(填空)"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"O7ekcGWXvcXu"},"outputs":[],"source":["def updateBN():\n","  for m in model.modules():\n","      if isinstance(m, nn.BatchNorm2d):\n","          #### 完成Sparsity Regularization ####\n","          ################################################\n","          #          請填空          #\n","          ################################################\n","          m.weight.grad.data.add_(LAMBDA*torch.sign(m.weight.data))\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"PAD78g28ns_C"},"source":["## 載入預先定義好的模型與參數"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"HKUUpjTan4Zq"},"outputs":[],"source":["if(RESUME):\n","  checkpoint = torch.load(WEIGHT_PATH)\n","  model.load_state_dict(checkpoint['state_dict'])\n","  optimizer.load_state_dict(checkpoint['optimizer'])\n","  START_EPOCH = checkpoint['epoch'] \n","  best_prec1 = checkpoint['best_prec1']\n","  print(f'RESUME MODEL @EPOCH={START_EPOCH}, BEST_PREC1={best_prec1}')"]},{"cell_type":"markdown","metadata":{"id":"gR2UTh0iwbEF"},"source":["## 定義訓練跟測試函數"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hQcKuMDee46V"},"outputs":[],"source":["#### 訓練函數 #####\n","\n","train_acc, train_loss = [], []\n","test_acc, test_loss = [], []\n","\n","# 注意: 需自行撰寫儲存每個epoch之train acc的code，以便後續繪製train acc結果圖!\n","def train(epoch):\n","    model.train()\n","    accuracy_per_epoch, loss_per_epoch = [], []\n","    for batch_idx, (data, target) in enumerate(train_loader):\n","        if CUDA:\n","            data, target = data.cuda(), target.cuda()\n","        data, target = Variable(data), Variable(target)\n","        optimizer.zero_grad()\n","        output = model(data)\n","        loss = F.cross_entropy(output, target)\n","        loss.backward()\n","\n","        if SPARSITY_REGULARIZATION:\n","            updateBN()\n","        optimizer.step()\n","        if batch_idx % LOG_INTERVAL == 0:\n","            print('Train Epoch: {} [{}/{} ({:.1f}%)]\\tLoss: {:.6f}'.format(\n","                epoch, batch_idx * len(data), len(train_loader.dataset),\n","                100. * batch_idx / len(train_loader), loss.data.item()))\n","            \n","        # 計算並儲存當前epoch之training accuracy\n","        pred = output.data.max(1, keepdim=True)[1]\n","        correct = pred.eq(target.data.view_as(pred)).cpu().sum()\n","        accuracy = correct / float(len(data))\n","        accuracy_per_epoch.append(accuracy)\n","        # 計算並儲存當前epoch之training loss\n","        loss_per_epoch.append(loss.data.item())\n","\n","    train_acc.append(sum(accuracy_per_epoch)/len(accuracy_per_epoch))\n","    train_loss.append(sum(loss_per_epoch)/len(loss_per_epoch))\n","    print(f'Train Epoch: {epoch}\\t Average Loss: {train_loss[-1]:.6f}\\t Average Accuracy: {train_acc[-1]:.6f}')\n","        \n","\n","\n","\n","#### 測試函數 ####\n","def test():\n","    model.eval()\n","    test_loss = 0\n","    correct = 0\n","    with torch.no_grad():\n","      for data, target in test_loader:\n","          if CUDA:\n","              data, target = data.cuda(), target.cuda()\n","          data, target = Variable(data), Variable(target)\n","          output = model(data)\n","          test_loss += F.cross_entropy(output, target, reduction='sum').data.item()\n","          pred = output.data.max(1, keepdim=True)[1]\n","          correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n","\n","      test_loss /= len(test_loader.dataset)\n","      print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.1f}%)\\n'.format(\n","          test_loss, correct, len(test_loader.dataset),\n","          100. * correct / len(test_loader.dataset)))\n","      return correct / float(len(test_loader.dataset))\n","\n","best_prec1 = 0.\n","for epoch in range(START_EPOCH, EPOCHS):\n","    # Learning Rate在0.5EPOCHS與0.75EPOCHS調整為原本1/10\n","    if epoch in [EPOCHS*0.5, EPOCHS*0.75]:\n","        for param_group in optimizer.param_groups:\n","            param_group['lr'] *= 0.1\n","    train(epoch)\n","    prec1 = test()\n","\n","    # 儲存模型權重，方便做後續剪枝,後續訓練\n","    if(prec1 > best_prec1):\n","        torch.save({\n","            'epoch': epoch + 1,\n","            'state_dict': model.state_dict(),\n","            'best_prec1': best_prec1,\n","            'optimizer': optimizer.state_dict(),\n","        }, WEIGHT_PATH)\n","\n","    best_prec1 = max(prec1, best_prec1)\n"]},{"cell_type":"markdown","metadata":{"id":"pPoQuFgx3mD9"},"source":["##繪製Sparsity-Training結果圖"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"x7O2cE4q52A-"},"outputs":[],"source":["#繪製 Sparsity-Training 結果圖\n","import matplotlib.pyplot as plt\n","import numpy as np\n","\n","plt.figure(figsize=(12, 4))\n","plt.subplot(1,2,1)\n","plt.title('Accuracy')\n","plt.plot(np.arange(1, EPOCHS+1), train_acc, label='Train')\n","plt.xlabel('Epochs')\n","plt.ylabel('Accuracy')\n","plt.legend(loc='best')\n","\n"]},{"cell_type":"markdown","metadata":{"id":"nw_CWhNSC7wT"},"source":["## 繪製scaling factor 分布圖"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ohSv3VlZCyuM"},"outputs":[],"source":["#繪製 scaling factor 分布圖\n","plt.subplot(1,2,2)\n","plt.title('Scaling Factor Distribution')\n","plt.hist(model.scaling_factor.data.cpu().numpy(), bins=50)\n","plt.xlabel('Scaling Factor')\n","plt.ylabel('Count')\n","plt.tight_layout()\n","plt.savefig('sparsity_train.png', dpi=300)\n","plt.show()"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.4"}},"nbformat":4,"nbformat_minor":0}
