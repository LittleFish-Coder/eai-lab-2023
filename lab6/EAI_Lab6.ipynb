{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2X3yAheTVHy6"
      },
      "source": [
        "# **1.Import Pytorch**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bY5BfhsJVBXd"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models.feature_extraction as feature_extraction\n",
        "from torchsummary import summary\n",
        "\n",
        "import os\n",
        "import copy\n",
        "\n",
        "no_cuda = False\n",
        "use_gpu = not no_cuda and torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_gpu else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TWzRKQJ5VKIp"
      },
      "source": [
        "# **2.Load Fashion MNIST Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fdaU4h2sVGCi",
        "outputId": "8cc1cefe-07fe-4d64-d428-e471a67e779a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 26421880/26421880 [00:01<00:00, 20891683.39it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 29515/29515 [00:00<00:00, 339669.38it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4422102/4422102 [00:00<00:00, 6258375.26it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 5148/5148 [00:00<00:00, 10872244.21it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n",
            "\n"
          ]
        }
      ],
      "source": [
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "#Dataset\n",
        "train_dataset = torchvision.datasets.FashionMNIST(root='./data', train=True, transform=transform, download=True)\n",
        "test_dataset = torchvision.datasets.FashionMNIST(root='./data', train=False, transform=transform, download=True)\n",
        "\n",
        "#Dataloader\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sd0z1xEWVNMo"
      },
      "source": [
        "# **3.Create and train a NN model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fxfpJb5XVtCD"
      },
      "outputs": [],
      "source": [
        "class ToyModel(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.nn1 = nn.Linear(28*28, 120)\n",
        "    self.nn2 = nn.Linear(120, 84)\n",
        "    self.nn3 = nn.Linear(84, 10)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = x.view(-1, 28 * 28) #transform 28*28 figure to 784 vector\n",
        "    x = F.relu(self.nn1(x))\n",
        "    x = F.relu(self.nn2(x))\n",
        "    x = self.nn3(x)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zH5gJgf0Vx11",
        "outputId": "9a24fac0-4481-4aab-8ddb-9e84b1f06601"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Linear-1                  [-1, 120]          94,200\n",
            "            Linear-2                   [-1, 84]          10,164\n",
            "            Linear-3                   [-1, 10]             850\n",
            "================================================================\n",
            "Total params: 105,214\n",
            "Trainable params: 105,214\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.00\n",
            "Params size (MB): 0.40\n",
            "Estimated Total Size (MB): 0.41\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "FP32_model = ToyModel().to(device)\n",
        "summary(FP32_model,(1,28,28))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5n28iqPfWNz6"
      },
      "outputs": [],
      "source": [
        "#train model\n",
        "def train_loop(dataloader, model, loss_fn, optimizer):\n",
        "  size = len(dataloader.dataset)\n",
        "  #Set the model to train mode\n",
        "  model.train()\n",
        "  for batch, (x, y) in enumerate(dataloader):\n",
        "    if use_gpu:\n",
        "      x, y = x.cuda(), y.cuda()\n",
        "    optimizer.zero_grad()\n",
        "    #forward\n",
        "    pred = model(x)\n",
        "\n",
        "    #loss\n",
        "    loss = loss_fn(pred, y)\n",
        "\n",
        "    #backward\n",
        "    loss.backward()\n",
        "\n",
        "    #optimize\n",
        "    optimizer.step()\n",
        "\n",
        "    if batch % 100 == 0:\n",
        "      loss, current = loss.item(), (batch + 1) * len(x)\n",
        "      print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "def test_loop(dataloader, model, loss_fn):\n",
        "  #set model to evaluate mode\n",
        "  model.eval()\n",
        "  size = len(dataloader.dataset)\n",
        "  num_batches = len(dataloader)\n",
        "  test_loss, correct = 0, 0\n",
        "  with torch.no_grad():\n",
        "    for x, y in dataloader:\n",
        "      if use_gpu:\n",
        "        x, y = x.cuda(), y.cuda()\n",
        "      pred = model(x)\n",
        "      test_loss = loss_fn(pred, y).item()\n",
        "      correct += (pred.argmax(1) == y).type(torch.float).sum().item() #calculate accuracy\n",
        "  test_loss /= num_batches\n",
        "  correct /= size\n",
        "  print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W4QeI-kqVzNN",
        "outputId": "60f8a229-ebe2-4f7a-c169-8725be1702f7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ToyModel(\n",
              "  (nn1): Linear(in_features=784, out_features=120, bias=True)\n",
              "  (nn2): Linear(in_features=120, out_features=84, bias=True)\n",
              "  (nn3): Linear(in_features=84, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "learning_rate = 1e-3\n",
        "epochs = 3\n",
        "loss_fn = nn.CrossEntropyLoss() #define loss function\n",
        "optimizer = torch.optim.SGD(FP32_model.parameters(), lr=learning_rate, momentum=0.9)  #define optimizer\n",
        "\n",
        "FP32_model.to(device) #let model on GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IdawCUguWQ39",
        "outputId": "fc72d917-b01e-48b5-b14f-8a5dfc90386c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 2.272040  [   32/60000]\n",
            "loss: 2.154126  [ 3232/60000]\n",
            "loss: 1.485687  [ 6432/60000]\n",
            "loss: 1.180371  [ 9632/60000]\n",
            "loss: 0.725408  [12832/60000]\n",
            "loss: 0.711334  [16032/60000]\n",
            "loss: 0.684661  [19232/60000]\n",
            "loss: 0.740626  [22432/60000]\n",
            "loss: 0.809315  [25632/60000]\n",
            "loss: 0.246356  [28832/60000]\n",
            "loss: 0.649688  [32032/60000]\n",
            "loss: 0.488470  [35232/60000]\n",
            "loss: 0.579858  [38432/60000]\n",
            "loss: 0.660828  [41632/60000]\n",
            "loss: 0.699628  [44832/60000]\n",
            "loss: 0.413648  [48032/60000]\n",
            "loss: 0.490594  [51232/60000]\n",
            "loss: 0.600312  [54432/60000]\n",
            "loss: 0.290745  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 80.2%, Avg loss: 0.001068 \n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 0.448714  [   32/60000]\n",
            "loss: 0.499115  [ 3232/60000]\n",
            "loss: 0.544766  [ 6432/60000]\n",
            "loss: 0.660541  [ 9632/60000]\n",
            "loss: 0.322607  [12832/60000]\n",
            "loss: 0.325584  [16032/60000]\n",
            "loss: 0.368600  [19232/60000]\n",
            "loss: 0.439019  [22432/60000]\n",
            "loss: 0.455746  [25632/60000]\n",
            "loss: 0.575191  [28832/60000]\n",
            "loss: 0.827715  [32032/60000]\n",
            "loss: 0.456415  [35232/60000]\n",
            "loss: 0.439917  [38432/60000]\n",
            "loss: 0.284277  [41632/60000]\n",
            "loss: 0.486166  [44832/60000]\n",
            "loss: 0.231441  [48032/60000]\n",
            "loss: 0.485719  [51232/60000]\n",
            "loss: 0.487235  [54432/60000]\n",
            "loss: 0.622481  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 83.0%, Avg loss: 0.000780 \n",
            "\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 0.381591  [   32/60000]\n",
            "loss: 0.464415  [ 3232/60000]\n",
            "loss: 0.321280  [ 6432/60000]\n",
            "loss: 0.343709  [ 9632/60000]\n",
            "loss: 0.483877  [12832/60000]\n",
            "loss: 0.395100  [16032/60000]\n",
            "loss: 0.414763  [19232/60000]\n",
            "loss: 0.498853  [22432/60000]\n",
            "loss: 0.323114  [25632/60000]\n",
            "loss: 0.583770  [28832/60000]\n",
            "loss: 0.555402  [32032/60000]\n",
            "loss: 0.441413  [35232/60000]\n",
            "loss: 0.680452  [38432/60000]\n",
            "loss: 0.327289  [41632/60000]\n",
            "loss: 0.620831  [44832/60000]\n",
            "loss: 0.414525  [48032/60000]\n",
            "loss: 0.288455  [51232/60000]\n",
            "loss: 0.527583  [54432/60000]\n",
            "loss: 0.317391  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 84.0%, Avg loss: 0.000676 \n",
            "\n"
          ]
        }
      ],
      "source": [
        "for i in range(epochs):\n",
        "  print(f\"Epoch {i+1}\\n-------------------------------\")\n",
        "  train_loop(train_loader, FP32_model, loss_fn, optimizer)\n",
        "  test_loop(test_loader, FP32_model, loss_fn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U8tQ69OJ9stN"
      },
      "source": [
        "# **4. Quantize**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nBFkGGLz-laW"
      },
      "source": [
        "下面兩格為需要實作的程式碼，請完成normal、clip的scale及zero point算法並且根據計算出來的s, z去進行tensor的quantize"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UuIlBblR-zhz"
      },
      "source": [
        "算法可以參考EAI Lab6 Page5、6的部分或是example的程式碼"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eWnx4WO8-Eqi"
      },
      "source": [
        "normal: 15%, clip: 15%, 結報請截圖實作部分的程式碼以及最後的兩種model的Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e0U9OtUOTfwE"
      },
      "outputs": [],
      "source": [
        "def Calculate_scale_zero_point(x, mode=\"normal\"):\n",
        "  if mode == \"normal\":\n",
        "    '''\n",
        "    請完成以下程式碼\n",
        "    '''\n",
        "    q_min, q_max = -128, 127  # int8\n",
        "    min_val, max_val = np.min(x.detach().numpy()), np.max(x.detach().numpy()) # get min/max value of x\n",
        "\n",
        "    scale = (max_val - min_val) / (q_max - q_min) # calculate scale\n",
        "    zero_point = round(q_min - min_val / scale) # calculate zero_point\n",
        "\n",
        "  elif mode == \"clip\":\n",
        "    '''\n",
        "    請完成以下程式碼\n",
        "    '''\n",
        "    q_min, q_max = -256, 255\n",
        "    min_val, max_val = np.min(x.detach().numpy()), np.max(x.detach().numpy()) # get min/max value of x\n",
        "\n",
        "    scale = (max_val - min_val) / (q_max - q_min) # calculate scale\n",
        "    zero_point = round(q_min - min_val / scale)\n",
        "\n",
        "  return scale, zero_point"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cgGxJQXVvuuA"
      },
      "outputs": [],
      "source": [
        "class Quantize_per_tensor(nn.Module):\n",
        "  def __init__(self, x, scale, zero_point, mode=\"normal\"):\n",
        "    super().__init__()\n",
        "    self.tensor = x\n",
        "    self.scale = scale\n",
        "    self.zero_point = zero_point\n",
        "    self._quantize(mode)\n",
        "\n",
        "  def repr(self):\n",
        "    return self.qtensor\n",
        "\n",
        "  def int_repr(self):\n",
        "    return self.qtensor_int\n",
        "\n",
        "  def _get_scale_zero(self):\n",
        "    return self.scale, self.zero_point\n",
        "\n",
        "  def _quantize(self, mode):\n",
        "    if mode == \"normal\":\n",
        "      self.qtensor_int = torch.round(self.tensor / self.scale + self.zero_point)  # q = round(r/s + zp)\n",
        "      self.qtensor = (self.qtensor_int - self.zero_point) * self.scale  # rq = (q - zp) * scale\n",
        "\n",
        "    elif mode == \"clip\":\n",
        "      self.qtensor_int = torch.round(self.tensor / self.scale + self.zero_point)\n",
        "      self.qtensor_int = torch.clamp(self.qtensor_int, -128, 127) # clamp to [-128, 127]\n",
        "      self.qtensor = (self.qtensor_int - self.zero_point) * self.scale"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9KPMGRRJ6LJe"
      },
      "outputs": [],
      "source": [
        "class QuantizedLinear(nn.Module):\n",
        "  def __init__(self, in_features, out_features, weight, bias, scale, zero_point, mode):\n",
        "    super(QuantizedLinear, self).__init__()\n",
        "    self.in_features = in_features\n",
        "    self.out_features = out_features\n",
        "    self.mode = mode\n",
        "    self.scale, self.zero_point = scale, zero_point\n",
        "    self.weight = self._weight_quantize(weight)\n",
        "    self.bias = bias\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = torch.matmul(x, self.weight.t())\n",
        "    output = Quantize_per_tensor(x, self.scale, self.zero_point, mode=self.mode).repr() + self.bias\n",
        "\n",
        "    return output\n",
        "\n",
        "  def _weight_quantize(self, weight):\n",
        "    s, z = Calculate_scale_zero_point(weight)\n",
        "    qweight = Quantize_per_tensor(weight, s, z, mode=self.mode)\n",
        "    return qweight.repr()\n",
        "\n",
        "  def __repr__(self):\n",
        "    return f'QuantizedLinear(in_features={self.in_features}, out_features={self.out_features}, scale={self.scale}, zero_point={self.zero_point})'\n",
        "\n",
        "class QuantizedLinearReLU(nn.Module):\n",
        "  def __init__(self, in_features, out_features, weight, bias, scale, zero_point, mode):\n",
        "    super(QuantizedLinearReLU, self).__init__()\n",
        "    self.in_features = in_features\n",
        "    self.out_features = out_features\n",
        "    self.mode = mode\n",
        "    self.scale, self.zero_point = scale, zero_point\n",
        "    self.weight = self._weight_quantize(weight)\n",
        "    self.bias = bias\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = torch.matmul(x, self.weight.t())\n",
        "    output = Quantize_per_tensor(x, self.scale, self.zero_point, mode=self.mode).repr() + self.bias\n",
        "    output = F.relu(output)\n",
        "    return output\n",
        "\n",
        "  def _weight_quantize(self, weight):\n",
        "    s, z = Calculate_scale_zero_point(weight)\n",
        "    qweight = Quantize_per_tensor(weight, s, z, mode=self.mode)\n",
        "    return qweight.repr()\n",
        "\n",
        "  def __repr__(self):\n",
        "    return f'QuantizedLinearReLU(in_features={self.in_features}, out_features={self.out_features}, scale={self.scale}, zero_point={self.zero_point})'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DAGugFzu6zcv"
      },
      "outputs": [],
      "source": [
        "class QuantizedModel(nn.Module):\n",
        "  def __init__(self, model, scale, zero_point, mode=\"normal\"):\n",
        "    super(QuantizedModel, self).__init__()\n",
        "    self.weight_dic = []\n",
        "    self.bias_dic = []\n",
        "    self.scale, self.zero_point = scale, zero_point #Scale and zero point of all layer\n",
        "    self.mode = mode\n",
        "\n",
        "    self._get_weight()\n",
        "    self.nn1 = QuantizedLinearReLU(in_features=28*28, out_features=120, weight=self.weight_dic[0], bias=self.bias_dic[0], scale=self.scale[1], zero_point=self.zero_point[1], mode=self.mode)\n",
        "    self.nn2 = QuantizedLinearReLU(in_features=120, out_features=84, weight=self.weight_dic[1], bias=self.bias_dic[1], scale=self.scale[2], zero_point=self.zero_point[2], mode=self.mode)\n",
        "    self.nn3 = QuantizedLinear(in_features=84, out_features=10, weight=self.weight_dic[2], bias=self.bias_dic[2], scale=self.scale[3], zero_point=self.zero_point[3], mode=self.mode)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = x.view(-1, 28 * 28)\n",
        "    x = Quantize_per_tensor(x, self.scale[0], self.zero_point[0], mode=self.mode).repr()\n",
        "    x = self.nn1(x)\n",
        "    x = self.nn2(x)\n",
        "    x = self.nn3(x)\n",
        "    x = x.dequantize()\n",
        "    return x\n",
        "\n",
        "  def _get_weight(self):\n",
        "    for name, paras in model.named_parameters():\n",
        "      if \"weight\" in name:\n",
        "        self.weight_dic.append(paras)\n",
        "      elif \"bias\" in name:\n",
        "        self.bias_dic.append(paras)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CHIbDajdAy1J"
      },
      "source": [
        "# Normal quantization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f9L2a2wUlhmy"
      },
      "outputs": [],
      "source": [
        "model = copy.deepcopy(FP32_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zVHUCwHh9sSj"
      },
      "outputs": [],
      "source": [
        "scale_dic = []\n",
        "zero_dic = []\n",
        "\n",
        "#Calibrate to compute s、z of all layer at the same time\n",
        "for batch in train_loader:\n",
        "  input, label = batch\n",
        "  for node in ['x', 'relu', 'relu_1', 'nn3']:\n",
        "    extractor = feature_extraction.create_feature_extractor(model, [node]).cpu()\n",
        "    output = extractor(input)[node]\n",
        "    q_min, q_max = -128, 127\n",
        "    min_val, max_val = np.min(output.detach().numpy()), np.max(output.detach().numpy())\n",
        "    scale = (max_val - min_val) / (q_max - q_min)\n",
        "    zero = round(q_min - min_val / scale)\n",
        "    q = Quantize_per_tensor(output, scale=scale, zero_point=zero, mode=\"normal\")\n",
        "    scale_dic.append(scale)\n",
        "    zero_dic.append(zero)\n",
        "  break\n",
        "\n",
        "print(scale_dic)\n",
        "print(zero_dic)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tpEEanUq8HQH"
      },
      "outputs": [],
      "source": [
        "Quantized_normal_model = QuantizedModel(model, scale_dic, zero_dic, mode=\"normal\")\n",
        "print(Quantized_normal_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2aEedHo2BFHy"
      },
      "source": [
        "# Clip quantization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "InrJuJoiBD0u"
      },
      "outputs": [],
      "source": [
        "model = copy.deepcopy(FP32_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8keSxS7xBUVq"
      },
      "outputs": [],
      "source": [
        "scale_dic = []\n",
        "zero_dic = []\n",
        "\n",
        "#Calibrate to compute s、z of all layer at the same time\n",
        "for batch in train_loader:\n",
        "  input, label = batch\n",
        "  for node in ['x', 'relu', 'relu_1', 'nn3']:\n",
        "    extractor = feature_extraction.create_feature_extractor(model, [node]).cpu()\n",
        "    output = extractor(input)[node]\n",
        "    q_min, q_max = -128, 127\n",
        "    min_val, max_val = np.min(output.detach().numpy()), np.max(output.detach().numpy())\n",
        "    scale = (max_val - min_val) / (q_max - q_min)\n",
        "    zero = round(q_min - min_val / scale)\n",
        "    q = Quantize_per_tensor(output, scale=scale, zero_point=zero, mode=\"clip\")\n",
        "    scale_dic.append(scale)\n",
        "    zero_dic.append(zero)\n",
        "  break\n",
        "\n",
        "print(scale_dic)\n",
        "print(zero_dic)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rq8CHZEgBXZh"
      },
      "outputs": [],
      "source": [
        "Quantized_clip_model = QuantizedModel(model, scale_dic, zero_dic, mode=\"clip\")\n",
        "print(Quantized_clip_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3aQIb5Ln8toE"
      },
      "outputs": [],
      "source": [
        "#define evaluate function\n",
        "def Evaluate(model, loader):\n",
        "  total = 0\n",
        "  correct = 0\n",
        "  with torch.no_grad():\n",
        "    for data in loader:\n",
        "      images, labels = data\n",
        "      outputs = model(images)\n",
        "      # the class with the highest energy is what we choose as prediction\n",
        "      _, predicted = torch.max(outputs.data, 1)\n",
        "      total += labels.size(0)\n",
        "      correct += (predicted == labels).sum().item()\n",
        "\n",
        "  test_loss = 0\n",
        "\n",
        "  print(\"========================================= PERFORMANCE =============================================\")\n",
        "  print('\\nAccuracy: {}/{} ({:.0f}%)\\n'.format( correct, total,100. * correct / total))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "04PMmzZSBwUp"
      },
      "outputs": [],
      "source": [
        "#Normal quantize\n",
        "Evaluate(Quantized_normal_model, test_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6giaE2PoB6Zd"
      },
      "outputs": [],
      "source": [
        "#Clip quantize\n",
        "Evaluate(Quantized_clip_model, test_loader)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
